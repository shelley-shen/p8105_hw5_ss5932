---
title: "Homework 5"
author: "Shelley Shen"
date: "11/14/2020"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(ggplot2)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


### Problem 1

Read in the data.

```{r}
homicide_df = 
  read_csv("homicide_data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```


Create an aggregate DF

```{r}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Proportion test for a single city

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Iterate for all cities

```{r}
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```


```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


### Problem 2

Read in data and create dataframe.

```{r, error = TRUE}
path_df = 
  tibble(
    path = list.files("lda_data")) %>% 
  mutate(
    path = str_c("lda_data/", path),
    data = map(.x = path, ~read_csv(.x))) %>% 
  unnest(data)
```

Tidy the data.

```{r}
path_tidy =
  path_df %>% 
  separate(path, into = c("folder", "arm"), sep = 9) %>% 
  separate(arm, into = c("arm", "id"), sep = "_") %>% 
  separate(id, into = c("id", "file"), sep = 2) %>% 
  select(-folder, -file) %>% 
  mutate(
    id = str_remove(id, "0"),
    arm = str_replace_all(arm, c("con" = "control", "exp" = "experimental"))
    ) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "value",
    names_prefix = "week_")
```

Create a spaghetti plot showing observations on each subject over time.

```{r}
lda_plot = 
  path_tidy %>% 
  group_by(arm, id) %>% 
  ggplot(
    aes(x = week, y = value, group = id, color = id)) +
  geom_point() +
  geom_line() +
  geom_point(alpha = 0.5) +
  facet_grid(arm ~.) +
  labs(
    title = "Observations for control vs. experimental arms over time",
    x = "Week of Observation",
    y = "Values"
  )
```

From the spaghetti plot, we see that generally, the experimental group had higher observation values than the control group. While the experimental group observations increased over time, the control group remained consistent without any significant changes overall. The consistency of the control arm is reasonable as it did not receive any treatment, and any change within the control is likely due to a placebo effect. 


### Question 3

Creating the t-test function.

```{r}
t_test = function(sample_size = 30, mu, sigma = 5) {
  simulation = 
    tibble(x = rnorm(n = sample_size, mean = mu, sd = sigma))
  simulation %>% 
  t.test() %>% 
  broom::tidy()
}
```

Set µ = 0 

```{r}
sim_results = 
  rerun(5000, t_test(mu = 0)) %>% 
  bind_rows()
sim_results %>% 
  select(estimate, p.value)
```

Repeat for means 1 to 6.

```{r}
rep_sim_results = 
  tibble(mean = c(0, 1, 2, 3, 4, 5, 6)) %>% 
  mutate(
    output_lists = map(.x = mean, ~rerun(5000, t_test(mu = .x))),
    estimate_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs)
rep_sim_results %>% 
  select(mean, estimate, p.value)
```

Create plot showing proportion of times the null was rejected vs true value of µ

```{r}
rep_sim_results %>% 
  select(mean, estimate, p.value) %>% 
  group_by(mean) %>% 
  summarize(prop_reject = sum(p.value <= 0.05) / n()) %>% 
  ggplot(aes(x = mean, y = prop_reject, fill = mean)) +
  geom_bar(stat = 'identity') +
  labs(
    title = "Proportion null rejected given true µ",
    x = "True µ",
    y = "Test power"
  )
```

The plot shows that as the true mean increases, the effect size increases and also causes an increase of power for the study. 


## Create plot showing average estimate of true and estimated μ

```{r}
all_samp = 
  rep_sim_results %>% 
    select(mean, estimate, p.value) %>% 
    group_by(mean) %>% 
    summarize(all = mean(estimate))

rejected_samp = 
  rep_sim_results %>% 
    select(mean, estimate, p.value) %>% 
    filter(p.value <= 0.05) %>% 
    group_by(mean) %>% 
    summarize(null_reject = mean(estimate))
  
left_join(all_samp, rejected_samp, by = "mean") %>% 
  pivot_longer(
    all:null_reject,
    names_to = "sample",
    values_to = "average_estimate"
  ) %>% 
  ggplot(aes(x = mean, y = average_estimate, color = sample)) +
  geom_line() +
  labs(
    title = "Average estimate of µ versus true µ",
    x = "True µ",
    y = "Average estimate of µ"
  )
```

The plot shows that the average estimate of µ is not the same as that of all the samples. The average estimate of µ does get closer though as the true µ increases and gets further away from 0. 